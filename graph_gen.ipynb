{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4955669-8364-4bea-8fed-5843fb1d7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##layer.py\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn.pool.topk_pool import topk,filter_adj\n",
    "from torch.nn import Parameter\n",
    "import torch\n",
    "\n",
    "\n",
    "class SAGPool(torch.nn.Module):\n",
    "    def __init__(self,in_channels,ratio=0.8,Conv=GCNConv,non_linearity=torch.tanh):\n",
    "        super(SAGPool,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.ratio = ratio\n",
    "        self.score_layer = Conv(in_channels,1)\n",
    "        self.non_linearity = non_linearity\n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        #x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        score = self.score_layer(x,edge_index).squeeze()\n",
    "        #the following two lines are added to fix a bug (IndexError)\n",
    "        if len(score.size()) == 0:\n",
    "            score = score.unsqueeze(0)\n",
    "        perm = topk(score, self.ratio, batch)\n",
    "        x = x[perm] * self.non_linearity(score[perm]).view(-1, 1)\n",
    "        batch = batch[perm]\n",
    "        edge_index, edge_attr = filter_adj(\n",
    "            edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
    "\n",
    "        return x, edge_index, edge_attr, batch, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caea7ee4-8896-4c17-b40a-b20eeb2b8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##utils.py\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "def get_adj(data):\n",
    "    edge_index = data.edge_index\n",
    "    n = data.x.shape[0]\n",
    "    adj = torch.zeros([n,n])\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        j = edge_index[0,i].item()\n",
    "        k = edge_index[1,i].item()\n",
    "    #     print(adj[j,k],adj[k,j])\n",
    "    #     print(j,k)\n",
    "        adj[j,k]=1\n",
    "    #     print(\"edge_added\")\n",
    "    #     print(adj[j,k],adj[k,j])\n",
    "    return adj\n",
    "# def recon_loss(data,pred_adj):\n",
    "#     criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#     return criterion(get_adj(data),pred_adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0bd14ab-a28c-4043-9ba9-9e6905d18727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import node\n",
    "from numpy import std\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn.models import InnerProductDecoder\n",
    "import torch.nn.functional as F\n",
    "from layers import SAGPool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from utils import get_adj\n",
    "class GraphEncoder(torch.nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.num_features = args.num_features\n",
    "        self.nhid = args.nhid\n",
    "        self.pooling_ratio = args.pooling_ratio\n",
    "        self.dropout_ratio = args.dropout_ratio\n",
    "        self.variational = args.variational\n",
    "        # Encoder Layers\n",
    "        self.conv1 = GCNConv(self.num_features, self.nhid)\n",
    "        self.pool1 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        self.conv2 = GCNConv(self.nhid, self.nhid)\n",
    "        self.pool2 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        self.conv3 = GCNConv(self.nhid, self.nhid)\n",
    "        self.pool3 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        # #Latent Layer transformation for Graph VAE\n",
    "        if self.variational:\n",
    "            self.latent_embeding_size = args.latent_embeding_size\n",
    "            self.mu_transform = torch.nn.Linear(self.nhid*2, self.latent_embeding_size)\n",
    "            self.log_var_transform = torch.nn.Linear(self.nhid*2, self.latent_embeding_size)\n",
    "\n",
    "    def forward(self,data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "        # # Latent transformation layers for mu and sigma \n",
    "        if self.variational:\n",
    "            mu = self.mu_transform(x)\n",
    "            log_var = self.log_var_transform(x)\n",
    "            return mu,log_var\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class GraphDecoder(torch.nn.Module):\n",
    "    def __init__(self,args) -> None:\n",
    "        super(GraphDecoder,self).__init__()\n",
    "        self.args = args\n",
    "        self.num_node_features = args.num_node_features\n",
    "        self.nhid = args.nhid\n",
    "        self.decoder_hidden_size = args.decoder_hidden_size\n",
    "        self.max_num_nodes = args.max_num_nodes\n",
    "        self.output_dim = args.max_num_nodes*(args.max_num_nodes-1)//2\n",
    "        self.latent_embeding_size = args.latent_embeding_size\n",
    "        self.variational = args.variational\n",
    "        self.linear1 = torch.nn.Linear(self.latent_embeding_size, self.decoder_hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(self.decoder_hidden_size, self.output_dim)\n",
    "        self.linear3 = torch.nn.Linear(self.decoder_hidden_size,self.num_node_features*self.max_num_nodes)\n",
    "\n",
    "    def forward(self,z):\n",
    "        x = F.leaky_relu(self.linear1(z))\n",
    "        adj_upper = self.linear2(x)\n",
    "        adj_upper = torch.sigmoid(adj_upper)\n",
    "        adj = self.recon_adj(adj_upper)\n",
    "        node_features= F.leaky_relu(self.linear3(x))\n",
    "        node_features = node_features.view(self.max_num_nodes,self.num_node_features)\n",
    "        return adj,node_features\n",
    "    \n",
    "    def recon_adj(self,adj_upper):\n",
    "        adj = torch.zeros(self.max_num_nodes,self.max_num_nodes)\n",
    "        adj[torch.triu(torch.ones(self.max_num_nodes,self.max_num_nodes),diagonal=1)==1] = adj_upper\n",
    "        diag = torch.diag(torch.diag(adj, 0))\n",
    "        adj = adj + torch.transpose(adj, 0, 1) - diag\n",
    "        return adj\n",
    "    \n",
    "    def recon_loss(self,data,adj_pred,node_features_pred):\n",
    "        adj_recon_loss = F.mse_loss(get_adj(data),adj_pred)\n",
    "        node_features_recon_loss = F.mse_loss(data.x,node_features_pred)\n",
    "        loss = adj_recon_loss + node_features_recon_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba4117c-f8a2-4b88-aa43-96dbdbf1eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--seed SEED] [--batch_size BATCH_SIZE]\n",
      "                             [--lr LR] [--weight_decay WEIGHT_DECAY]\n",
      "                             [--pooling_ratio POOLING_RATIO]\n",
      "                             [--dropout_ratio DROPOUT_RATIO]\n",
      "                             [--dataset DATASET] [--epochs EPOCHS]\n",
      "                             [--val_epochs VAL_EPOCHS] [--patience PATIENCE]\n",
      "                             [--pooling_layer_type POOLING_LAYER_TYPE]\n",
      "                             [--use_node_attr USE_NODE_ATTR]\n",
      "                             [--variational VARIATIONAL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/soham/.local/share/jupyter/runtime/kernel-66fbff8f-50e5-4010-b20d-b71ca8cf3ddb.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soham/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "## train.py\n",
    "import torch_geometric.nn as nn\n",
    "from model import GraphEncoder,GraphDecoder\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric import utils\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataset import Subset\n",
    "from utils import get_adj\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=777,\n",
    "                    help='seed')\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--lr', type=float, default=0.0008,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0001,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--pooling_ratio', type=float, default=0.5,\n",
    "                    help='pooling ratio')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.5,\n",
    "                    help='dropout ratio')\n",
    "parser.add_argument('--dataset', type=str, default='BOTDS',\n",
    "                    help='dataset sub-directory under dir: data. e.g. BOTDS')\n",
    "parser.add_argument('--epochs', type=int, default=1000,\n",
    "                    help='maximum number of epochs')\n",
    "parser.add_argument('--val_epochs', type=int, default=25,\n",
    "                    help='maximum number of validation epochs')\n",
    "parser.add_argument('--patience', type=int, default=50,\n",
    "                    help='patience for earlystopping')\n",
    "parser.add_argument('--pooling_layer_type', type=str, default='GCNConv',\n",
    "                    help='type of pooling layer')\n",
    "parser.add_argument('--use_node_attr', type=bool, default=True,\n",
    "                    help='node features')\n",
    "parser.add_argument('--variational', type=bool, default=False,\n",
    "                    help='Varitional Graph Auto Encoder')\n",
    "\n",
    "#Load GPU (If present)\n",
    "args = parser.parse_args()\n",
    "# args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.device = torch.device(\"cpu\")\n",
    "dataset = TUDataset('data',name = args.dataset,use_node_attr=args.use_node_attr)\n",
    "args.nhid = 128\n",
    "args.num_features = dataset.num_features\n",
    "args.num_node_features = dataset.num_node_features\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "args.max_num_nodes = 75\n",
    "args.variational = True\n",
    "args.latent_embeding_size = args.nhid*2\n",
    "args.decoder_hidden_size = args.latent_embeding_size*4\n",
    "if args.variational:\n",
    "    model = nn.VGAE(GraphEncoder(args),GraphDecoder(args))\n",
    "else:\n",
    "    model = nn.GAE(GraphEncoder(args),GraphDecoder(args))\n",
    "model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = args.lr,weight_decay=args.weight_decay)\n",
    "j =0\n",
    "## Total 46 examples of sizes 75 nodes 40 for training remaining 6 for training\n",
    "for i,data in enumerate(loader):\n",
    "    if data.num_nodes == args.max_num_nodes:\n",
    "        j=j+1\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(data)\n",
    "        adj,node_features= model.decode(z)\n",
    "        loss = model.decoder.recon_loss(data,adj,node_features)\n",
    "        if args.variational:\n",
    "            loss = loss + model.kl_loss()\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(j>40):\n",
    "            break\n",
    "j=0\n",
    "for i,data in enumerate(loader):\n",
    "    if data.num_nodes == args.max_num_nodes:\n",
    "        j=j+1\n",
    "        if j<=40:\n",
    "            continue\n",
    "        z = model.encode(data)\n",
    "        adj,node_features= model.decode(z)\n",
    "        loss = model.decoder.recon_loss(data,adj,node_features)\n",
    "        if args.variational:\n",
    "            loss = loss + model.kl_loss()\n",
    "        print(f\"loss:{loss}\")\n",
    "        # print(adj)\n",
    "        # print(get_adj(data))\n",
    "        # print(node_features)\n",
    "        \n",
    "\n",
    "\n",
    "# num_training = int(len(dataset)*0.6)\n",
    "# num_val = int(len(dataset)*0.1)\n",
    "# num_test = len(dataset) - (num_training+num_val)\n",
    "# training_set,validation_set,test_set = random_split(dataset,[num_test,num_training,num_val])\n",
    "# train_loader = DataLoader(training_set, batch_size=1, shuffle=True)\n",
    "# val_loader = DataLoader(validation_set, batch_size=1, shuffle=False)\n",
    "# test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "# it = test_loader._get_iterator()\n",
    "# sample = it.next()\n",
    "# # print(dataset.num_node_features)\n",
    "# # print(sample.batch,sample.x)\n",
    "# print(get_adj(sample))\n",
    "# z= model.encode(sample)\n",
    "# adj,node_features,loss= model.decode(sample,z)\n",
    "# print(adj,adj.shape)\n",
    "# print(node_features,node_features.shape)\n",
    "# print(criterion(get_adj(sample),adj),loss)\n",
    "# # loss = model.recon_loss(z.t(),sample.edge_index)\n",
    "# # print(loss)\n",
    "# # print(criterion(get_adj(sample),adj))\n",
    "# loss = 0\n",
    "# epoch_loss = []\n",
    "\n",
    "# for epoch in range(2):\n",
    "#     model.train()\n",
    "#     for i,data in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         z = model.encode(data)\n",
    "#         adj,node_features,loss = model.decode(data,z)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     model.eval()\n",
    "#     avg_loss =0\n",
    "#     for i,data in enumerate(val_loader):\n",
    "#         z = model.encode(data)\n",
    "#         adj,node_features,loss = model.decode(data,z)\n",
    "#         avg_loss += loss\n",
    "#     epoch_loss.append(avg_loss/(i+1))\n",
    "#     print(f'epoch: {epoch} avg loss: {epoch_loss[epoch]}')\n",
    "# print(epoch_loss)\n",
    "# z= model.encode(sample)\n",
    "# adj,node_features,loss = model.decode(sample,z)\n",
    "# print(adj,adj.shape)\n",
    "# print(adj,node_features.shape)\n",
    "# print(sample.x,sample.x.shape)\n",
    "# print(loss)\n",
    "# print(criterion(get_adj(sample),adj))\n",
    "# print(criterion(sample.x,node_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aae15d-114e-430d-8e76-a62f94a2b1bd",
   "metadata": {},
   "source": [
    "Graph Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93cadb8-9c12-4918-ad1d-3dcc36d8b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "tensor(0.2635, grad_fn=<AddBackward0>)\n",
      "tensor(0.2603, grad_fn=<AddBackward0>)\n",
      "tensor(0.2578, grad_fn=<AddBackward0>)\n",
      "tensor(0.2546, grad_fn=<AddBackward0>)\n",
      "tensor(0.2515, grad_fn=<AddBackward0>)\n",
      "tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "tensor(0.2392, grad_fn=<AddBackward0>)\n",
      "tensor(0.2303, grad_fn=<AddBackward0>)\n",
      "tensor(0.2203, grad_fn=<AddBackward0>)\n",
      "tensor(0.2051, grad_fn=<AddBackward0>)\n",
      "tensor(0.1929, grad_fn=<AddBackward0>)\n",
      "tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "tensor(0.1630, grad_fn=<AddBackward0>)\n",
      "tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "tensor(0.1243, grad_fn=<AddBackward0>)\n",
      "tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "tensor(0.0661, grad_fn=<AddBackward0>)\n",
      "tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "tensor(0.0609, grad_fn=<AddBackward0>)\n",
      "tensor(0.0622, grad_fn=<AddBackward0>)\n",
      "tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "tensor(0.0636, grad_fn=<AddBackward0>)\n",
      "tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "Started Validation\n",
      "loss:0.0924396961927414\n",
      "tensor([[0.0000, 0.0292, 0.0309,  ..., 0.0305, 0.0317, 0.0305],\n",
      "        [0.0292, 0.0000, 0.0300,  ..., 0.0292, 0.0308, 0.0299],\n",
      "        [0.0309, 0.0300, 0.0000,  ..., 0.0304, 0.0304, 0.0306],\n",
      "        ...,\n",
      "        [0.0305, 0.0292, 0.0304,  ..., 0.0000, 0.0294, 0.0308],\n",
      "        [0.0317, 0.0308, 0.0304,  ..., 0.0294, 0.0000, 0.0323],\n",
      "        [0.0305, 0.0299, 0.0306,  ..., 0.0308, 0.0323, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 8.2093e-01, -1.4822e-04, -6.1500e-05,  ..., -3.9568e-04,\n",
      "         -8.5614e-05,  8.6428e-01],\n",
      "        [ 1.0202e+00, -2.0023e-05, -5.8512e-05,  ..., -1.6733e-04,\n",
      "         -3.2681e-07,  8.8059e-01],\n",
      "        [ 9.0963e-01,  6.7615e-04, -1.1260e-04,  ..., -6.7824e-05,\n",
      "         -1.1161e-05,  9.3015e-01],\n",
      "        ...,\n",
      "        [-4.5928e-04, -1.4162e-04, -2.5279e-04,  ..., -5.4995e-05,\n",
      "          8.8796e-04,  1.0259e+00],\n",
      "        [-3.8391e-05, -8.4089e-05, -8.2429e-05,  ..., -3.0441e-05,\n",
      "         -3.2597e-04,  1.0797e+00],\n",
      "        [-1.2919e-04, -1.3466e-05, -1.8540e-04,  ..., -4.3561e-05,\n",
      "         -3.1373e-04,  8.5072e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.06529583036899567\n",
      "tensor([[0.0000, 0.0343, 0.0363,  ..., 0.0357, 0.0370, 0.0357],\n",
      "        [0.0343, 0.0000, 0.0352,  ..., 0.0343, 0.0361, 0.0351],\n",
      "        [0.0363, 0.0352, 0.0000,  ..., 0.0356, 0.0357, 0.0358],\n",
      "        ...,\n",
      "        [0.0357, 0.0343, 0.0356,  ..., 0.0000, 0.0345, 0.0360],\n",
      "        [0.0370, 0.0361, 0.0357,  ..., 0.0345, 0.0000, 0.0378],\n",
      "        [0.0357, 0.0351, 0.0358,  ..., 0.0360, 0.0378, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 7.8692e-01, -1.4046e-04, -5.9165e-05,  ..., -3.7804e-04,\n",
      "         -8.5588e-05,  8.2600e-01],\n",
      "        [ 9.7029e-01, -1.5476e-05, -5.3328e-05,  ..., -1.5136e-04,\n",
      "         -3.7564e-07,  8.4326e-01],\n",
      "        [ 8.7421e-01,  6.1671e-04, -1.0797e-04,  ..., -6.1969e-05,\n",
      "         -9.1294e-06,  8.8415e-01],\n",
      "        ...,\n",
      "        [-4.3752e-04, -1.3289e-04, -2.3781e-04,  ..., -5.4438e-05,\n",
      "          8.7861e-04,  9.7323e-01],\n",
      "        [-4.1143e-05, -7.7570e-05, -8.5880e-05,  ..., -3.1535e-05,\n",
      "         -3.0317e-04,  1.0243e+00],\n",
      "        [-1.2499e-04, -6.5949e-06, -1.7430e-04,  ..., -4.5360e-05,\n",
      "         -2.9502e-04,  8.0979e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.08568364381790161\n",
      "tensor([[0.0000, 0.0227, 0.0241,  ..., 0.0238, 0.0248, 0.0238],\n",
      "        [0.0227, 0.0000, 0.0234,  ..., 0.0226, 0.0240, 0.0233],\n",
      "        [0.0241, 0.0234, 0.0000,  ..., 0.0237, 0.0237, 0.0239],\n",
      "        ...,\n",
      "        [0.0238, 0.0226, 0.0237,  ..., 0.0000, 0.0229, 0.0240],\n",
      "        [0.0248, 0.0240, 0.0237,  ..., 0.0229, 0.0000, 0.0254],\n",
      "        [0.0238, 0.0233, 0.0239,  ..., 0.0240, 0.0254, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 8.7964e-01, -1.6077e-04, -5.9662e-05,  ..., -4.2221e-04,\n",
      "         -9.1759e-05,  9.1840e-01],\n",
      "        [ 1.0952e+00, -3.2133e-05, -5.6246e-05,  ..., -1.8468e-04,\n",
      "         -4.0006e-06,  9.4641e-01],\n",
      "        [ 9.7524e-01,  1.2869e-03, -1.2036e-04,  ..., -7.5974e-05,\n",
      "         -1.0805e-05,  9.9938e-01],\n",
      "        ...,\n",
      "        [-4.9247e-04, -1.5070e-04, -2.6822e-04,  ..., -5.7958e-05,\n",
      "          1.1328e-03,  1.0996e+00],\n",
      "        [-4.4479e-05, -8.7731e-05, -9.0980e-05,  ..., -2.7645e-05,\n",
      "         -3.5381e-04,  1.1562e+00],\n",
      "        [-1.4281e-04, -1.1218e-05, -2.0583e-04,  ..., -4.6957e-05,\n",
      "         -3.3721e-04,  9.0578e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.07846362143754959\n",
      "tensor([[0.0000, 0.0374, 0.0393,  ..., 0.0387, 0.0402, 0.0387],\n",
      "        [0.0374, 0.0000, 0.0383,  ..., 0.0372, 0.0392, 0.0382],\n",
      "        [0.0393, 0.0383, 0.0000,  ..., 0.0385, 0.0388, 0.0389],\n",
      "        ...,\n",
      "        [0.0387, 0.0372, 0.0385,  ..., 0.0000, 0.0375, 0.0391],\n",
      "        [0.0402, 0.0392, 0.0388,  ..., 0.0375, 0.0000, 0.0408],\n",
      "        [0.0387, 0.0382, 0.0389,  ..., 0.0391, 0.0408, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 7.6687e-01, -1.3822e-04, -5.9124e-05,  ..., -3.6925e-04,\n",
      "         -8.8223e-05,  8.0993e-01],\n",
      "        [ 9.4782e-01, -1.0432e-05, -5.6076e-05,  ..., -1.5275e-04,\n",
      "          2.5234e-05,  8.1791e-01],\n",
      "        [ 8.5327e-01,  2.4270e-04, -1.0478e-04,  ..., -5.9433e-05,\n",
      "         -6.5725e-06,  8.6050e-01],\n",
      "        ...,\n",
      "        [-4.2517e-04, -1.3006e-04, -2.3460e-04,  ..., -5.6131e-05,\n",
      "          1.4126e-03,  9.5315e-01],\n",
      "        [-3.8634e-05, -7.2803e-05, -8.3999e-05,  ..., -3.0544e-05,\n",
      "         -2.9143e-04,  1.0044e+00],\n",
      "        [-1.1709e-04, -1.2170e-05, -1.6596e-04,  ..., -4.4419e-05,\n",
      "         -2.8251e-04,  7.9275e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.0610835999250412\n",
      "tensor([[0.0000, 0.0346, 0.0366,  ..., 0.0360, 0.0373, 0.0360],\n",
      "        [0.0346, 0.0000, 0.0354,  ..., 0.0346, 0.0364, 0.0354],\n",
      "        [0.0366, 0.0354, 0.0000,  ..., 0.0359, 0.0360, 0.0361],\n",
      "        ...,\n",
      "        [0.0360, 0.0346, 0.0359,  ..., 0.0000, 0.0348, 0.0363],\n",
      "        [0.0373, 0.0364, 0.0360,  ..., 0.0348, 0.0000, 0.0380],\n",
      "        [0.0360, 0.0354, 0.0361,  ..., 0.0363, 0.0380, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 7.8403e-01, -1.4072e-04, -5.9531e-05,  ..., -3.7639e-04,\n",
      "         -8.5325e-05,  8.2378e-01],\n",
      "        [ 9.6794e-01, -1.5929e-05, -5.4841e-05,  ..., -1.5133e-04,\n",
      "         -1.2561e-07,  8.3953e-01],\n",
      "        [ 8.7176e-01,  5.8767e-04, -1.0640e-04,  ..., -6.1832e-05,\n",
      "         -8.4053e-06,  8.8160e-01],\n",
      "        ...,\n",
      "        [-4.3677e-04, -1.3238e-04, -2.3774e-04,  ..., -5.4626e-05,\n",
      "          8.8975e-04,  9.7156e-01],\n",
      "        [-3.9828e-05, -7.6871e-05, -8.4711e-05,  ..., -2.9935e-05,\n",
      "         -3.0370e-04,  1.0228e+00],\n",
      "        [-1.2407e-04, -7.3992e-06, -1.7280e-04,  ..., -4.4541e-05,\n",
      "         -2.9460e-04,  8.0748e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.0723336860537529\n",
      "tensor([[0.0000, 0.0362, 0.0382,  ..., 0.0377, 0.0390, 0.0377],\n",
      "        [0.0362, 0.0000, 0.0371,  ..., 0.0363, 0.0381, 0.0371],\n",
      "        [0.0382, 0.0371, 0.0000,  ..., 0.0375, 0.0376, 0.0378],\n",
      "        ...,\n",
      "        [0.0377, 0.0363, 0.0375,  ..., 0.0000, 0.0364, 0.0380],\n",
      "        [0.0390, 0.0381, 0.0376,  ..., 0.0364, 0.0000, 0.0398],\n",
      "        [0.0377, 0.0371, 0.0378,  ..., 0.0380, 0.0398, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 7.7007e-01, -1.3905e-04, -6.0259e-05,  ..., -3.7211e-04,\n",
      "         -8.3355e-05,  8.1295e-01],\n",
      "        [ 9.5345e-01, -1.3228e-05, -5.5028e-05,  ..., -1.4821e-04,\n",
      "         -1.0950e-06,  8.2775e-01],\n",
      "        [ 8.5844e-01,  5.3473e-04, -1.0567e-04,  ..., -6.1661e-05,\n",
      "         -1.1701e-05,  8.7043e-01],\n",
      "        ...,\n",
      "        [-4.3090e-04, -1.2895e-04, -2.3502e-04,  ..., -5.2202e-05,\n",
      "          7.6327e-04,  9.5889e-01],\n",
      "        [-3.7630e-05, -7.8563e-05, -8.0510e-05,  ..., -2.9641e-05,\n",
      "         -2.9949e-04,  1.0098e+00],\n",
      "        [-1.1951e-04, -8.5811e-06, -1.6968e-04,  ..., -4.2559e-05,\n",
      "         -2.9199e-04,  7.9858e-01]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21128f2a-a736-4cb7-b873-49334989af09",
   "metadata": {},
   "source": [
    "Variational Graph Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab9fc29-2a59-4238-9fe6-ce63431b9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "tensor(0.8057, grad_fn=<AddBackward0>)\n",
      "tensor(0.7201, grad_fn=<AddBackward0>)\n",
      "tensor(0.6673, grad_fn=<AddBackward0>)\n",
      "tensor(0.6103, grad_fn=<AddBackward0>)\n",
      "tensor(0.5631, grad_fn=<AddBackward0>)\n",
      "tensor(0.5064, grad_fn=<AddBackward0>)\n",
      "tensor(0.4466, grad_fn=<AddBackward0>)\n",
      "tensor(0.3946, grad_fn=<AddBackward0>)\n",
      "tensor(0.3319, grad_fn=<AddBackward0>)\n",
      "tensor(0.2903, grad_fn=<AddBackward0>)\n",
      "tensor(0.2439, grad_fn=<AddBackward0>)\n",
      "tensor(0.2052, grad_fn=<AddBackward0>)\n",
      "tensor(0.2271, grad_fn=<AddBackward0>)\n",
      "tensor(0.2242, grad_fn=<AddBackward0>)\n",
      "tensor(0.1667, grad_fn=<AddBackward0>)\n",
      "tensor(0.2262, grad_fn=<AddBackward0>)\n",
      "tensor(0.1309, grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, grad_fn=<AddBackward0>)\n",
      "tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "tensor(0.1181, grad_fn=<AddBackward0>)\n",
      "tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "tensor(0.0657, grad_fn=<AddBackward0>)\n",
      "tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "tensor(0.1012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "Started Validation\n",
      "loss:0.22316186130046844\n",
      "tensor([[0.0000, 0.4390, 0.4247,  ..., 0.4256, 0.4361, 0.4369],\n",
      "        [0.4390, 0.0000, 0.4361,  ..., 0.4331, 0.4267, 0.4332],\n",
      "        [0.4247, 0.4361, 0.0000,  ..., 0.4253, 0.4280, 0.4249],\n",
      "        ...,\n",
      "        [0.4256, 0.4331, 0.4253,  ..., 0.0000, 0.4386, 0.4312],\n",
      "        [0.4361, 0.4267, 0.4280,  ..., 0.4386, 0.0000, 0.4389],\n",
      "        [0.4369, 0.4332, 0.4249,  ..., 0.4312, 0.4389, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 1.1211e-01, -3.6473e-04, -4.9613e-04,  ..., -4.2930e-04,\n",
      "         -2.4305e-04,  7.4630e-02],\n",
      "        [ 1.0467e-01, -1.6233e-04, -2.5640e-04,  ..., -1.4608e-04,\n",
      "         -4.5139e-04,  7.2715e-02],\n",
      "        [ 1.1717e-01, -4.0360e-04, -2.0199e-04,  ..., -3.6815e-04,\n",
      "         -5.1511e-04,  1.3330e-01],\n",
      "        ...,\n",
      "        [-3.3273e-04, -9.3909e-05, -1.2572e-04,  ..., -5.6250e-04,\n",
      "         -1.4287e-04,  1.0139e-01],\n",
      "        [-3.3543e-04, -1.7032e-04, -3.4852e-04,  ..., -7.1929e-05,\n",
      "         -4.1594e-04,  6.4246e-02],\n",
      "        [-6.0416e-05, -1.4754e-04, -2.8585e-04,  ..., -1.0965e-04,\n",
      "         -2.2784e-04,  1.3587e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.21652574837207794\n",
      "tensor([[0.0000, 0.4391, 0.4251,  ..., 0.4255, 0.4363, 0.4371],\n",
      "        [0.4391, 0.0000, 0.4364,  ..., 0.4329, 0.4268, 0.4334],\n",
      "        [0.4251, 0.4364, 0.0000,  ..., 0.4253, 0.4281, 0.4249],\n",
      "        ...,\n",
      "        [0.4255, 0.4329, 0.4253,  ..., 0.0000, 0.4391, 0.4315],\n",
      "        [0.4363, 0.4268, 0.4281,  ..., 0.4391, 0.0000, 0.4391],\n",
      "        [0.4371, 0.4334, 0.4249,  ..., 0.4315, 0.4391, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 1.1184e-01, -3.6691e-04, -4.9662e-04,  ..., -4.2207e-04,\n",
      "         -2.3844e-04,  7.3360e-02],\n",
      "        [ 1.0558e-01, -1.6274e-04, -2.5181e-04,  ..., -1.4473e-04,\n",
      "         -4.4378e-04,  7.2364e-02],\n",
      "        [ 1.1620e-01, -4.0122e-04, -2.0338e-04,  ..., -3.6808e-04,\n",
      "         -5.1403e-04,  1.3199e-01],\n",
      "        ...,\n",
      "        [-3.3196e-04, -9.1078e-05, -1.2527e-04,  ..., -5.6447e-04,\n",
      "         -1.4793e-04,  1.0105e-01],\n",
      "        [-3.3450e-04, -1.7080e-04, -3.5501e-04,  ..., -7.2052e-05,\n",
      "         -4.1875e-04,  6.3965e-02],\n",
      "        [-5.8184e-05, -1.5296e-04, -2.8239e-04,  ..., -1.0592e-04,\n",
      "         -2.2881e-04,  1.3598e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.21878620982170105\n",
      "tensor([[0.0000, 0.4389, 0.4247,  ..., 0.4255, 0.4361, 0.4369],\n",
      "        [0.4389, 0.0000, 0.4362,  ..., 0.4330, 0.4266, 0.4333],\n",
      "        [0.4247, 0.4362, 0.0000,  ..., 0.4252, 0.4279, 0.4248],\n",
      "        ...,\n",
      "        [0.4255, 0.4330, 0.4252,  ..., 0.0000, 0.4388, 0.4313],\n",
      "        [0.4361, 0.4266, 0.4279,  ..., 0.4388, 0.0000, 0.4390],\n",
      "        [0.4369, 0.4333, 0.4248,  ..., 0.4313, 0.4390, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 1.1191e-01, -3.6664e-04, -4.9621e-04,  ..., -4.2687e-04,\n",
      "         -2.4124e-04,  7.4457e-02],\n",
      "        [ 1.0533e-01, -1.6271e-04, -2.5335e-04,  ..., -1.4661e-04,\n",
      "         -4.5021e-04,  7.2438e-02],\n",
      "        [ 1.1652e-01, -4.0352e-04, -2.0200e-04,  ..., -3.6795e-04,\n",
      "         -5.1332e-04,  1.3258e-01],\n",
      "        ...,\n",
      "        [-3.3012e-04, -9.2607e-05, -1.2527e-04,  ..., -5.6145e-04,\n",
      "         -1.4333e-04,  1.0133e-01],\n",
      "        [-3.3601e-04, -1.6919e-04, -3.5259e-04,  ..., -7.0550e-05,\n",
      "         -4.1851e-04,  6.4570e-02],\n",
      "        [-5.9711e-05, -1.5009e-04, -2.8404e-04,  ..., -1.0702e-04,\n",
      "         -2.3043e-04,  1.3604e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.21747107803821564\n",
      "tensor([[0.0000, 0.4393, 0.4252,  ..., 0.4258, 0.4366, 0.4372],\n",
      "        [0.4393, 0.0000, 0.4366,  ..., 0.4332, 0.4269, 0.4335],\n",
      "        [0.4252, 0.4366, 0.0000,  ..., 0.4255, 0.4283, 0.4252],\n",
      "        ...,\n",
      "        [0.4258, 0.4332, 0.4255,  ..., 0.0000, 0.4389, 0.4315],\n",
      "        [0.4366, 0.4269, 0.4283,  ..., 0.4389, 0.0000, 0.4392],\n",
      "        [0.4372, 0.4335, 0.4252,  ..., 0.4315, 0.4392, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 1.1148e-01, -3.6314e-04, -4.9534e-04,  ..., -4.2314e-04,\n",
      "         -2.4188e-04,  7.3049e-02],\n",
      "        [ 1.0542e-01, -1.6124e-04, -2.5397e-04,  ..., -1.4393e-04,\n",
      "         -4.4389e-04,  7.2524e-02],\n",
      "        [ 1.1667e-01, -3.9988e-04, -2.0252e-04,  ..., -3.6782e-04,\n",
      "         -5.1580e-04,  1.3272e-01],\n",
      "        ...,\n",
      "        [-3.3267e-04, -9.2150e-05, -1.2574e-04,  ..., -5.6271e-04,\n",
      "         -1.4653e-04,  1.0053e-01],\n",
      "        [-3.3316e-04, -1.7317e-04, -3.5155e-04,  ..., -7.4842e-05,\n",
      "         -4.1580e-04,  6.3722e-02],\n",
      "        [-5.8843e-05, -1.5061e-04, -2.8235e-04,  ..., -1.0730e-04,\n",
      "         -2.2302e-04,  1.3534e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.21717306971549988\n",
      "tensor([[0.0000, 0.4390, 0.4247,  ..., 0.4256, 0.4362, 0.4368],\n",
      "        [0.4390, 0.0000, 0.4362,  ..., 0.4331, 0.4266, 0.4332],\n",
      "        [0.4247, 0.4362, 0.0000,  ..., 0.4253, 0.4281, 0.4250],\n",
      "        ...,\n",
      "        [0.4256, 0.4331, 0.4253,  ..., 0.0000, 0.4386, 0.4312],\n",
      "        [0.4362, 0.4266, 0.4281,  ..., 0.4386, 0.0000, 0.4388],\n",
      "        [0.4368, 0.4332, 0.4250,  ..., 0.4312, 0.4388, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 1.1240e-01, -3.6520e-04, -4.9777e-04,  ..., -4.2758e-04,\n",
      "         -2.4455e-04,  7.4363e-02],\n",
      "        [ 1.0468e-01, -1.6228e-04, -2.5617e-04,  ..., -1.4541e-04,\n",
      "         -4.4981e-04,  7.3034e-02],\n",
      "        [ 1.1756e-01, -4.0224e-04, -2.0148e-04,  ..., -3.6760e-04,\n",
      "         -5.1664e-04,  1.3326e-01],\n",
      "        ...,\n",
      "        [-3.3129e-04, -9.3637e-05, -1.2569e-04,  ..., -5.6386e-04,\n",
      "         -1.4668e-04,  1.0109e-01],\n",
      "        [-3.3483e-04, -1.7195e-04, -3.4983e-04,  ..., -7.3997e-05,\n",
      "         -4.1620e-04,  6.4423e-02],\n",
      "        [-5.9903e-05, -1.4973e-04, -2.8460e-04,  ..., -1.0877e-04,\n",
      "         -2.2834e-04,  1.3597e-01]], grad_fn=<ViewBackward0>)\n",
      "loss:0.21683482825756073\n",
      "tensor([[0.0000, 0.4391, 0.4250,  ..., 0.4257, 0.4365, 0.4371],\n",
      "        [0.4391, 0.0000, 0.4364,  ..., 0.4331, 0.4268, 0.4334],\n",
      "        [0.4250, 0.4364, 0.0000,  ..., 0.4254, 0.4282, 0.4251],\n",
      "        ...,\n",
      "        [0.4257, 0.4331, 0.4254,  ..., 0.0000, 0.4388, 0.4314],\n",
      "        [0.4365, 0.4268, 0.4282,  ..., 0.4388, 0.0000, 0.4391],\n",
      "        [0.4371, 0.4334, 0.4251,  ..., 0.4314, 0.4391, 0.0000]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 1.1172e-01, -3.6463e-04, -4.9320e-04,  ..., -4.2300e-04,\n",
      "         -2.4116e-04,  7.3428e-02],\n",
      "        [ 1.0538e-01, -1.6155e-04, -2.5390e-04,  ..., -1.4374e-04,\n",
      "         -4.4278e-04,  7.2656e-02],\n",
      "        [ 1.1657e-01, -4.0050e-04, -2.0360e-04,  ..., -3.6930e-04,\n",
      "         -5.1637e-04,  1.3291e-01],\n",
      "        ...,\n",
      "        [-3.3403e-04, -9.2323e-05, -1.2575e-04,  ..., -5.6357e-04,\n",
      "         -1.4789e-04,  1.0104e-01],\n",
      "        [-3.3417e-04, -1.7337e-04, -3.5134e-04,  ..., -7.4958e-05,\n",
      "         -4.1581e-04,  6.3572e-02],\n",
      "        [-5.8688e-05, -1.5111e-04, -2.8313e-04,  ..., -1.0797e-04,\n",
      "         -2.2560e-04,  1.3568e-01]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --variational True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d38e0-af58-45b2-aa78-5b158594e736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
